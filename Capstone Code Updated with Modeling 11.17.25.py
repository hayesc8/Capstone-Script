#!/usr/bin/env python3
# -*- coding: utf-8 -*-


# NOTE: Portions of this script (matching heuristics, parsing helpers, caching, retry logic,
# borderline match export, and additional feature engineering/modeling) were added or adapted
# from suggestions generated by ChatGPT (GPT-5 Thinking mini) on Oct 17, 2025.

#------------------------------------------------------------
#This was added to assist with certificate issues with nba_api
#--------------------------------------------------------------
import warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
from urllib3.exceptions import InsecureRequestWarning
warnings.filterwarnings("ignore", category=InsecureRequestWarning)
#------------------------------------------------------------------------------------
import re
import time
import pickle
from pathlib import Path
import pandas as pd
import numpy as np
from rapidfuzz import process, fuzz
from tqdm import tqdm
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, stats
from itertools import combinations
import requests
import os
from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor, NearestNeighbors
from sklearn.multioutput import MultiOutputRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.inspection import permutation_importance



# ---------------------------
# FILE PATHS
# ---------------------------
INPUT_CSV = "NBA Player Injury Stats(1951 - 2023).csv"
CACHE_PATH = Path("nba_logs_cache.pkl")
ALL_LOGS_CSV = "all_nba_logs.csv"
OUT_MODEL_CSV = "acl_modeling_dataset_features.csv"
OUT_RAW_MODEL_CSV = "acl_modeling_dataset.csv"
OUT_UNMATCHED = "unmatched_acl_players.csv"
OUT_BORDERLINE = "borderline_matches_to_verify.csv"
MANUAL_OVERRIDES = "manual_overrides.csv"
FEATURE_MAP_CSV = "feature_row_mapping.csv"   # new: mapping from injury row -> feature row

# Parameters
SEASON_PAD = 2
RETURN_GAP_DAYS = 90
PRE_N, POST_N = 20, 20
MIN_GAMES_EACH = 10
FUZZY_STRONG = 85
FUZZY_BORDER_LOW = 70

# EDA plot
SAVE_PLOTS = True   # set False to skip plot image saving
PLOTS_DIR = Path("eda_plots")
PLOTS_DIR.mkdir(exist_ok=True)

# ---------------------------
# HELPERS
# ---------------------------
def name_variants(name):
    if not name or pd.isna(name):
        return []
    n = str(name).strip()
    n_nosuffix = re.sub(r'\b(JR|SR|II|III|IV|V)\b\.?', '', n, flags=re.I).strip()
    n_nosuffix = re.sub(r'\s+', ' ', n_nosuffix)
    variants = [n, n_nosuffix]
    if "," in n_nosuffix:
        parts = [p.strip() for p in n_nosuffix.split(",")]
        if len(parts) >= 2:
            variants.append(f"{parts[1]} {parts[0]}")
    parts = n_nosuffix.split()
    if len(parts) >= 2:
        first_last = " ".join(parts)
        last_first = f"{parts[-1]}, {' '.join(parts[:-1])}"
        variants.extend([first_last, last_first])
    if len(parts) >= 3:
        variants.append(f"{parts[0]} {parts[-1]}")
        variants.append(f"{parts[0]} {parts[1]} {parts[-1]}")
    seen = set()
    uniq = []
    for v in variants:
        if v and v not in seen:
            seen.add(v)
            uniq.append(v)
    return uniq

def get_top_candidates(query, choices, limit=5):
    return [(r[0], r[1]) for r in process.extract(query, choices, scorer=fuzz.WRatio, limit=limit)]

def resolve_player_id_two_step(name, nba_names, nba_id_map, threshold_strong=FUZZY_STRONG, threshold_borderline_low=FUZZY_BORDER_LOW):
    if not name or pd.isna(name):
        return None, None, None, "empty", []
    if name in nba_id_map:
        return nba_id_map[name], name, 100, "exact", [(name, 100)]
    for variant in name_variants(name):
        if variant in nba_id_map:
            return nba_id_map[variant], variant, 100, "variant_exact", [(variant, 100)]
    best_score = -1
    best_match = None
    top_candidates_for_output = []
    for variant in name_variants(name):
        top = get_top_candidates(variant, nba_names, limit=5)
        if top and not top_candidates_for_output:
            top_candidates_for_output = top
        if top:
            cand_name, cand_score = top[0]
            if cand_score > best_score:
                best_score = cand_score
                best_match = cand_name
    if best_score < 0:
        return None, None, None, "no_candidates", []
    if best_score >= threshold_strong:
        return nba_id_map.get(best_match), best_match, best_score, "fuzzy_strong", top_candidates_for_output
    elif best_score >= threshold_borderline_low:
        return nba_id_map.get(best_match), best_match, best_score, "fuzzy_borderline", top_candidates_for_output
    else:
        return None, best_match, best_score, "fuzzy_weak", top_candidates_for_output

def robust_parse_min(min_str):
    if pd.isna(min_str):
        return np.nan
    s = str(min_str).strip()
    try:
        if ":" in s:
            mm, ss = s.split(":", 1)
            mm = float(mm) if mm else 0.0
            ss = float(re.sub(r'[^0-9.]', '', ss)) if ss else 0.0
            return mm + ss / 60.0
        if re.match(r'^\d+(\.\d+)?$', s):
            return float(s)
        found = re.search(r'\d+(\.\d+)?', s)
        return float(found.group(0)) if found else np.nan
    except Exception:
        return np.nan

def safe_mean(series):
    if series is None:
        return np.nan
    if not hasattr(series, "dropna"):
        try:
            return float(series)
        except Exception:
            return np.nan
    s = series.dropna()
    return float(s.mean()) if not s.empty else np.nan

def tidy_logs(df_logs):
    if df_logs is None or df_logs.empty:
        return pd.DataFrame()
    df_logs = df_logs.copy()
    df_logs["GAME_DATE"] = pd.to_datetime(df_logs["GAME_DATE"], errors="coerce")
    # canonicalize a few common column name variants (map aliases -> canonical)
    # Will check and rename if present
    alias_map = {
        "3PM": ["3PM","FG3M","FG3_PTS","FG3M."],
        "3PA": ["3PA","FG3A","FG3A."],
        "3P_PCT": ["3P_PCT","FG3_PCT","FG3_PCT."],
        "FG_PCT": ["FG_PCT","FG_PCT."],
        "FT_PCT": ["FT_PCT","FT_PCT."],
        "MIN": ["MIN","MP","MINUTES"]
    }
    for canon, aliases in alias_map.items():
        for a in aliases:
            if a in df_logs.columns and canon not in df_logs.columns:
                df_logs = df_logs.rename(columns={a: canon})
                break
    # coerce numeric columns that commonly exist
    for c in ["PTS","AST","REB","FGM","FGA","FG_PCT","3PM","3PA","3P_PCT","FTM","FTA","FT_PCT","TOV","PF","STL","BLK"]:
        if c in df_logs.columns:
            df_logs[c] = pd.to_numeric(df_logs[c], errors="coerce")
    if "MIN" in df_logs.columns:
        df_logs["MIN"] = df_logs["MIN"].map(robust_parse_min)
    df_logs = df_logs.sort_values("GAME_DATE").reset_index(drop=True)
    return df_logs

def fetch_player_logs_oneoff(pid, seasons):
    """
    requests-based fetch (verify=False). Used as fallback per-season.
    """
    all_logs = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Referer": "https://www.nba.com/",
        "Origin": "https://www.nba.com",
        "Accept": "application/json, text/plain, */*",
    }
    for season in seasons:
        url = f"https://stats.nba.com/stats/playergamelog?PlayerID={pid}&Season={season}&SeasonType=Regular%20Season"
        try:
            resp = requests.get(url, verify=False, headers=headers, timeout=10)
            resp.raise_for_status()
            data = resp.json()
            df = pd.DataFrame(data['resultSets'][0]['rowSet'], columns=data['resultSets'][0]['headers'])
            all_logs.append(df)
        except Exception as e:
            print(f"[error] Exception for pid={pid}, season={season}: {repr(e)}")
        time.sleep(1.5)
    if all_logs:
        return pd.concat(all_logs, ignore_index=True)
    return pd.DataFrame()

# plotting helper
def save_for_slide(fig, fname, width=10, height=6):
    if not SAVE_PLOTS:
        plt.close(fig)
        return
    fig.set_size_inches(width, height)
    fig.tight_layout(pad=1.0)
    path = PLOTS_DIR / fname
    fig.savefig(path, dpi=150, bbox_inches="tight")
    plt.close(fig)

# ---------------------------
# LOAD INJURY Data
# ---------------------------
print("Loading injury CSV...")
df = pd.read_csv(INPUT_CSV)
df = df.drop(columns=["Unnamed: 0"], errors="ignore")
df["player_raw"] = df["Relinquished"].fillna("").astype(str).str.strip()
df["injury"] = df["Notes"].fillna("").astype(str)
df["is_acl"] = df["injury"].str.contains(r"\bacl\b|anterior\s+cruciate", case=False, regex=True)
df["date"] = pd.to_datetime(df["Date"], errors="coerce")
df = df.dropna(subset=["date", "player_raw"])
df_acl = df[df["is_acl"] & (df["date"].dt.year >= 1996)].copy().reset_index(drop=True)
print(f"Found {len(df_acl)} ACL rows (1996+).")

# ---------------------------
# NBA players list
# ---------------------------
from nba_api.stats.static import players as nba_players
all_players = nba_players.get_players()
nba_names = [p["full_name"] for p in all_players]
nba_id_map = {p["full_name"]: p["id"] for p in all_players}

if CACHE_PATH.exists():
    try:
        with open(CACHE_PATH, "rb") as f:
            cache_logs = pickle.load(f)
        print(f"Loaded cached logs for {len(cache_logs)} players.")
    except Exception as e:
        print(f"[warn] Failed to load cache: {repr(e)}. Starting with empty cache.")
        cache_logs = {}
else:
    cache_logs = {}

def load_manual_overrides(path=MANUAL_OVERRIDES):
    overrides = {}
    p = Path(path)
    if not p.exists():
        return overrides
    df_ov = pd.read_csv(p)
    for _, r in df_ov.iterrows():
        k = str(r.get("original_player", "")).strip()
        v = r.get("confirmed_full_name_or_id", "")
        if pd.isna(v) or v == "":
            continue
        v_str = str(v).strip()
        if v_str.isdigit():
            overrides[k] = int(v_str)
        else:
            if v_str in nba_id_map:
                overrides[k] = nba_id_map[v_str]
            else:
                top = get_top_candidates(v_str, nba_names, limit=1)
                if top and top[0][1] >= FUZZY_STRONG:
                    overrides[k] = nba_id_map.get(top[0][0])
                else:
                    print(f"[warn] manual override '{v_str}' not resolvable for original_player '{k}'")#added to troubleshoot 
    return overrides

manual_overrides = load_manual_overrides()

# ---------------------------
# MAIN LOOP - map injuries to logs and compute pre/post
# ---------------------------
rows = []
unmatched = []
borderline_records = []

for _, r in tqdm(df_acl.iterrows(), total=len(df_acl), desc="Processing ACL rows"):
    original_name = r["player_raw"]
    year = r["date"].year

    if not original_name or pd.isna(original_name):
        unmatched.append({"player": original_name, "injury_year": year, "reason": "missing name"})
        continue

    # split ambiguous names if possible
    pname = original_name
    if any(sep in pname for sep in ["/", "&", " and "]):
        candidate = re.split(r'/|&|\band\b', pname, flags=re.I)[0].strip()
        if len(candidate) < 2:
            unmatched.append({"player": pname, "injury_year": year, "reason": "ambiguous after split"})
            continue
        pname = candidate

    # manual override?
    pid_override = manual_overrides.get(original_name)
    if pid_override:
        pid = pid_override
        matched_name = next((name for name, pidv in nba_id_map.items() if pidv == pid), None)
        match_score = 100
        match_method = "manual_override"
        top_cands = [(matched_name, 100)] if matched_name else []
    else:
        pid, matched_name, match_score, match_method, top_cands = resolve_player_id_two_step(
            pname, nba_names=nba_names, nba_id_map=nba_id_map, threshold_strong=FUZZY_STRONG, threshold_borderline_low=FUZZY_BORDER_LOW
        )

    if match_method == "fuzzy_borderline":
        borderline_records.append({
            "original_player": original_name,
            "injury_year": year,
            "chosen_match": matched_name,
            "match_score": match_score,
            "match_method": match_method,
            "top_candidates": "; ".join([f"{c[0]} ({c[1]})" for c in top_cands])
        })

    if not pid:
        unmatched.append({"player": original_name, "injury_year": year, "best_match": matched_name, "score": match_score, "method": match_method})
        continue

    inj_date = r["date"]
    seasons = [f"{y}-{str((y+1)%100).zfill(2)}" for y in range(inj_date.year - SEASON_PAD, inj_date.year + SEASON_PAD + 1)]

    if pid not in cache_logs:
        # trying nba_api playergamelog with fallback to requestsm based oneoff fetch per season
        try:
            from nba_api.stats.endpoints import playergamelog
            raw_logs = []
            for s in seasons:
                try:
                    gl = playergamelog.PlayerGameLog(player_id=pid, season=s, timeout=30).get_data_frames()[0]
                    if gl is not None and not gl.empty:
                        raw_logs.append(gl)
                    time.sleep(0.6)
                except Exception:
                    df_one = fetch_player_logs_oneoff(pid, [s])
                    if not df_one.empty:
                        raw_logs.append(df_one)
            raw_logs = pd.concat(raw_logs, ignore_index=True) if raw_logs else pd.DataFrame()
        except Exception:
            raw_logs = fetch_player_logs_oneoff(pid, seasons)

        logs = tidy_logs(raw_logs)
        cache_logs[pid] = logs
         
        try:
            with open(CACHE_PATH, "wb") as f:
                pickle.dump(cache_logs, f)
        except Exception as e:
            print(f"[warn] failed to persist cache: {repr(e)}")
    else:
        logs = cache_logs[pid]

    if logs is None or logs.empty:
        unmatched.append({"player": original_name, "injury_year": year, "reason": "no logs", "matched_name": matched_name})
        continue

    ret_date = logs[logs["GAME_DATE"] >= (inj_date + pd.Timedelta(days=RETURN_GAP_DAYS))]["GAME_DATE"].min()
    if pd.isna(ret_date):
        unmatched.append({"player": original_name, "injury_year": year, "reason": "no return date", "matched_name": matched_name})
        continue

    pre = logs[logs["GAME_DATE"] < inj_date].tail(PRE_N)
    post = logs[logs["GAME_DATE"] >= ret_date].head(POST_N)
    if len(pre) < MIN_GAMES_EACH or len(post) < MIN_GAMES_EACH:
        unmatched.append({"player": original_name, "injury_year": year, "reason": f"insufficient games pre={len(pre)} post={len(post)}", "matched_name": matched_name})
        continue

    row = {
        "player": original_name,
        "matched_name": matched_name,
        "injury_date": inj_date,
        "return_date": ret_date,
        "pre_n": len(pre),
        "post_n": len(post),
        "pre_pts_mean": safe_mean(pre.get("PTS")),
        "post_pts_mean": safe_mean(post.get("PTS")),
        "pre_ast_mean": safe_mean(pre.get("AST")),
        "post_ast_mean": safe_mean(post.get("AST")),
        "pre_reb_mean": safe_mean(pre.get("REB")),
        "post_reb_mean": safe_mean(post.get("REB")),
        "pre_min_mean": safe_mean(pre.get("MIN")),
        "post_min_mean": safe_mean(post.get("MIN")),
        "match_score": match_score,
        "match_method": match_method
    }
    for stat in ["pts", "ast", "reb", "min"]:
        a = row.get(f"pre_{stat}_mean")
        b = row.get(f"post_{stat}_mean")
        row[f"delta_{stat}"] = (b - a) if (pd.notna(a) and pd.notna(b)) else np.nan
        row[f"ratio_{stat}"] = (b / a) if (pd.notna(a) and a not in [0, 0.0, None]) else np.nan

    rows.append(row)

# ---------------------------
# Save outputs
# ---------------------------

#Added Print statements to help understand where the code was in running
model_df = pd.DataFrame(rows)
model_df.to_csv(OUT_RAW_MODEL_CSV, index=False)
print(f"[ok] Saved raw modeling dataset with {len(model_df)} rows -> {OUT_RAW_MODEL_CSV}")

unmatched_df = pd.DataFrame(unmatched)
unmatched_df.to_csv(OUT_UNMATCHED, index=False)
print(f"[ok] Saved unmatched player list with {len(unmatched_df)} rows -> {OUT_UNMATCHED}")

if borderline_records:
    borderline_df = pd.DataFrame(borderline_records).sort_values("match_score", ascending=False)
    borderline_df.to_csv(OUT_BORDERLINE, index=False)
    print(f"[ok] Saved {len(borderline_df)} borderline matches to '{OUT_BORDERLINE}'.")
else:
    print("[ok] No borderline matches found.")

# Save logs CSV #help with long rerunnng of data
try:
    if cache_logs:
        all_logs_df = pd.concat([df_.assign(player_id=pid) for pid, df_ in cache_logs.items() if not df_.empty], ignore_index=True)
        all_logs_df.to_csv(ALL_LOGS_CSV, index=False)
        print(f"[ok] Saved combined logs to {ALL_LOGS_CSV}")
except Exception as e:
    print(f"[warn] Failed to save combined logs CSV: {repr(e)}")

# ---------------------------
# FEATURE ENGINEERING (enhanced) + PCA with median imputation
# ---------------------------
print("Starting enhanced feature engineering and PCA...")

# Stats aliases to be tolerant of different column names in logs
stats_aliases = {
    "PTS": ["PTS"],
    "AST": ["AST"],
    "REB": ["REB"],
    "STL": ["STL"],
    "BLK": ["BLK"],
    "TOV": ["TOV"],
    "PF": ["PF"],
    "FGM": ["FGM"],
    "FGA": ["FGA"],
    "FG_PCT": ["FG_PCT"],
    "3PM": ["3PM", "FG3M", "FG3M."],
    "3PA": ["3PA", "FG3A", "FG3A."],
    "3P_PCT": ["3P_PCT", "FG3_PCT"],
    "FTM": ["FTM"],
    "FTA": ["FTA"],
    "FT_PCT": ["FT_PCT"],
    "MIN": ["MIN", "MP"]
}
# Build stats list keys
stats_cols = list(stats_aliases.keys())

feature_rows = []
feature_map = []  # whold mapping rows {injury_index, player, feature_index}
for inj_idx, r in tqdm(df_acl.iterrows(), total=len(df_acl), desc="Feature engineering"):
    player_name = r["player_raw"]
    inj_date = r["date"]
    # resolve id
    pid = manual_overrides.get(player_name)
    if pid is None:
        pid, _, _, _, _ = resolve_player_id_two_step(player_name, nba_names, nba_id_map)
    if pid is None or pid not in cache_logs:
        continue
    logs = cache_logs[pid]
    if logs is None or logs.empty:
        continue

    # find return date from injury
    ret_date = logs[logs["GAME_DATE"] >= (inj_date + pd.Timedelta(days=RETURN_GAP_DAYS))]["GAME_DATE"].min()
    if pd.isna(ret_date):
        continue

    pre_logs = logs[logs["GAME_DATE"] < inj_date].tail(PRE_N)
    post_logs = logs[logs["GAME_DATE"] >= ret_date].head(POST_N)
    if len(pre_logs) < MIN_GAMES_EACH or len(post_logs) < MIN_GAMES_EACH:
        continue

    feat = {"player": player_name, "player_id": pid, "injury_date": inj_date, "return_date": ret_date,
            "pre_n": len(pre_logs), "post_n": len(post_logs)}

    # For each  stat, find an available alias in logs and compute mean
    for canon in stats_cols:
        aliases = stats_aliases.get(canon, [canon])
        found_col = None
        for a in aliases:
            if a in logs.columns:
                found_col = a
                break
        if not found_col:
            feat[f"{canon}_pre_mean"] = np.nan
            feat[f"{canon}_post_mean"] = np.nan
            feat[f"{canon}_delta"] = np.nan
            continue
        pre_mean = safe_mean(pre_logs.get(found_col))
        post_mean = safe_mean(post_logs.get(found_col))
        feat[f"{canon}_pre_mean"] = pre_mean
        feat[f"{canon}_post_mean"] = post_mean
        feat[f"{canon}_delta"] = (post_mean - pre_mean) if (pd.notna(pre_mean) and pd.notna(post_mean)) else np.nan

    # compute efficiency from already created mean fields
    # EFF = PTS + REB + AST + STL + BLK - TOV - PF
    def compute_eff_from_feat_dict(fdict):
        pos_keys = ["PTS", "REB", "AST", "STL", "BLK"]
        neg_keys = ["TOV", "PF"]
        pre_vals = []
        post_vals = []
        for k in pos_keys:
            pre_vals.append(fdict.get(f"{k}_pre_mean", np.nan))
            post_vals.append(fdict.get(f"{k}_post_mean", np.nan))
        for k in neg_keys:
            pre_vals.append(-fdict.get(f"{k}_pre_mean", np.nan))
            post_vals.append(-fdict.get(f"{k}_post_mean", np.nan))
        pre_eff = safe_mean(pd.Series(pre_vals)) if any(pd.notna(pre_vals)) else np.nan
        post_eff = safe_mean(pd.Series(post_vals)) if any(pd.notna(post_vals)) else np.nan
        return pre_eff, post_eff

    eff_pre, eff_post = compute_eff_from_feat_dict(feat)
    feat["EFF_pre"] = eff_pre
    feat["EFF_post"] = eff_post
    feat["EFF_delta"] = eff_post - eff_pre if (pd.notna(eff_pre) and pd.notna(eff_post)) else np.nan

    feature_idx = len(feature_rows)
    feature_rows.append(feat)
    feature_map.append({"injury_index": inj_idx, "player": player_name, "feature_index": feature_idx})

df_features = pd.DataFrame(feature_rows)
print(f"[info] Created {len(df_features)} feature rows.")

# Save feature row mapping

pd.DataFrame(feature_map).to_csv(FEATURE_MAP_CSV, index=False)
print(f"[ok] Saved feature mapping -> {FEATURE_MAP_CSV}")

if df_features.empty:
    print("[warn] No feature rows created (df_features is empty). Skipping PCA & EDA.")
else:
    # Save raw features CSV for inspection and to be able to add to slides
    df_features.to_csv(OUT_RAW_MODEL_CSV, index=False)
    print(f"[ok] Saved raw feature dataset to {OUT_RAW_MODEL_CSV}")

    # Candidate features for PCA: all delta and EFF columns
    candidate_feats = [c for c in df_features.columns if (c.endswith("_delta") or c.startswith("EFF"))]
    print(f"[info] Candidate PCA features count: {len(candidate_feats)}")
    if not candidate_feats:
        print("[warn] No candidate features found for PCA.")
    else:
        # median imputation 
        X_raw = df_features[candidate_feats].replace([np.inf, -np.inf], np.nan)
        medians = X_raw.median(axis=0, skipna=True)
        X = X_raw.fillna(medians)  # fill with per-column median
        # if still NaN (all-NaN column), fill with 0 as last resort
        X = X.fillna(0)
        scaler = StandardScaler()
        Xs = scaler.fit_transform(X)
        n_comp = min(8, Xs.shape[1], Xs.shape[0])
        if n_comp <= 0:
            print("[warn] Not enough rows/cols for PCA (n_comp <= 0).")
        else:
            pca = PCA(n_components=n_comp)
            Xp = pca.fit_transform(Xs)
            df_pca = pd.DataFrame(Xp, columns=[f"PCA_{i+1}" for i in range(Xp.shape[1])])
            df_pca[["player","player_id","injury_date"]] = df_features[["player","player_id","injury_date"]].reset_index(drop=True)
            df_pca.to_csv(OUT_MODEL_CSV, index=False)
            print(f"[ok] Saved PCA-transformed feature dataset to {OUT_MODEL_CSV}")
            print("Explained variance ratio:", pca.explained_variance_ratio_)

    # ---------------------------
    # EDA plots
    # ---------------------------
    try:
        if SAVE_PLOTS and not df_features.empty:
            sns.set_style("whitegrid")
            plt.rcParams.update({"figure.dpi":150, "font.size":11})

            # 1) Descriptive stats table to CSV
            desc_cols = ["PTS_pre_mean","PTS_post_mean","PTS_delta","AST_pre_mean","AST_post_mean","AST_delta",
                         "REB_pre_mean","REB_post_mean","REB_delta","MIN_pre_mean","MIN_post_mean","MIN_delta","EFF_pre","EFF_post","EFF_delta"]
            desc_cols = [c for c in desc_cols if c in df_features.columns]
            if desc_cols:
                desc_df = df_features[desc_cols].describe().T
                desc_df.to_csv("desc_stats_for_slide.csv")

            # 2) Missingness bar (feedback it shouldn't be empty test)
            fig = plt.figure()
            missing = df_features.isna().sum().sort_values(ascending=True)
            missing.plot.barh(figsize=(8,4))
            plt.title("Missing values by column")
            plt.xlabel("Missing count")
            save_for_slide(fig, "missing_counts.png", width=8, height=4)

            # 3) Histograms for chosen numeric deltas 
            hist_targets = [c for c in df_features.columns if c.endswith("_delta")]
            hist_targets = hist_targets[:6]
            for c in hist_targets:
                fig = plt.figure()
                sns.histplot(df_features[c].dropna(), kde=True)
                sk = df_features[c].dropna().skew() if not df_features[c].dropna().empty else np.nan
                plt.title(f"{c} (skew={sk:.2f})")
                save_for_slide(fig, f"hist_{c}.png", width=6, height=4)

            # 4) Correlation heatmap of deltas and EFF
            corr_cols = [c for c in candidate_feats if c in df_features.columns]
            if len(corr_cols) >= 2:
                corr_df = df_features[corr_cols].corr()
                fig = plt.figure(figsize=(8,6))
                sns.heatmap(corr_df, annot=True, fmt=".2f", cmap="vlag", center=0, square=False)
                plt.title("Correlation matrix (Pearson r) - candidate features")
                save_for_slide(fig, "corr_heatmap.png", width=8, height=6)

            # 5) Paired boxplot for PTS 
            if "PTS_pre_mean" in df_features.columns and "PTS_post_mean" in df_features.columns:
                idx = df_features[["PTS_pre_mean","PTS_post_mean"]].dropna().index
                if len(idx) > 1:
                    a = df_features.loc[idx,"PTS_pre_mean"]
                    b = df_features.loc[idx,"PTS_post_mean"]
                    t_stat, p_val = stats.ttest_rel(a, b, nan_policy="omit")
                    cohen_d = (a - b).mean() / (a - b).std(ddof=1) if (a-b).std(ddof=1)!=0 else np.nan
                else:
                    t_stat, p_val, cohen_d = np.nan, np.nan, np.nan
                fig = plt.figure()
                df_plot = df_features.loc[idx, ["PTS_pre_mean","PTS_post_mean"]].melt(var_name="period", value_name="pts")
                sns.boxplot(x="period", y="pts", data=df_plot)
                sns.stripplot(x="period", y="pts", data=df_plot, color=".25", jitter=True, alpha=0.7)
                plt.title(f"Pre vs Post PTS  (paired t={t_stat:.2f}, p={p_val:.3f}, d={cohen_d:.2f})")
                save_for_slide(fig, "paired_pts_box.png", width=8, height=5)

            # 6) Recovery days vs delta_pts 
            if "PTS_delta" in df_features.columns and "injury_date" in df_features.columns and "return_date" in df_features.columns:
                df_features["recovery_days"] = (pd.to_datetime(df_features["return_date"]) - pd.to_datetime(df_features["injury_date"])).dt.days
                if df_features["recovery_days"].notna().sum() > 1:
                    fig = plt.figure()
                    sns.regplot(data=df_features, x="recovery_days", y="PTS_delta", scatter_kws={"alpha":0.6})
                    plt.xlabel("Recovery days")
                    plt.ylabel("Delta PTS (post - pre)")
                    plt.title("Recovery days vs Delta PTS")
                    save_for_slide(fig, "recovery_vs_delta_pts.png", width=8, height=5)

            # 7) PCA scree & scatter 
            if Path(OUT_MODEL_CSV).exists():
                pca_df = pd.read_csv(OUT_MODEL_CSV)
                pca_cols = [c for c in pca_df.columns if c.startswith("PCA_")]
                if len(pca_cols) >= 1:
                   
                    if candidate_feats:
                        X_tmp = df_features[candidate_feats].replace([np.inf, -np.inf], np.nan).fillna(df_features[candidate_feats].median()).fillna(0)
                        try:
                            Xs_tmp = StandardScaler().fit_transform(X_tmp)
                            n_comp_tmp = min(8, Xs_tmp.shape[1], Xs_tmp.shape[0])
                            if n_comp_tmp > 0:
                                pca_tmp = PCA(n_components=n_comp_tmp).fit(Xs_tmp)
                                expl = pca_tmp.explained_variance_ratio_
                                fig = plt.figure()
                                plt.bar(range(1, len(expl)+1), expl)
                                plt.xlabel("PC")
                                plt.ylabel("Explained variance ratio")
                                plt.title("PCA Scree (recomputed)")
                                save_for_slide(fig, "pca_scree.png", width=6, height=4)
                               
                                loadings = pd.DataFrame(pca_tmp.components_.T, index=candidate_feats, columns=[f"PC{i+1}" for i in range(pca_tmp.components_.shape[0])])
                                loadings.to_csv("pca_loadings.csv")
                                
                                if Xs_tmp.shape[0] >= 2 and pca_tmp.components_.shape[0] >= 2:
                                    pcs = pca_tmp.transform(Xs_tmp)[:,:2]
                                    proj_df = pd.DataFrame(pcs, columns=["PCA1","PCA2"])
                                    if "PTS_delta" in df_features.columns:
                                        proj_df = proj_df.join(df_features["PTS_delta"].reset_index(drop=True))
                                    fig = plt.figure()
                                    hue = "PTS_delta" if "PTS_delta" in proj_df.columns else None
                                    sns.scatterplot(data=proj_df, x="PCA1", y="PCA2", hue=hue, palette="tab10", alpha=0.85, legend="brief")
                                    plt.title("PCA: PC1 vs PC2")
                                    save_for_slide(fig, "pca_scatter.png", width=8, height=6)
                        except Exception as e:
                            print(f"[warn] PCA visuals failed: {e}")
#Added to assit with trouble shooting
            print("Saved EDA plots (if SAVE_PLOTS=True).")
    except Exception as e:
        print(f"[warn] EDA plotting error: {repr(e)}")

print("Enhanced feature engineering block complete.")
print("Pipeline finished.")

############################################### Model Building and Evaluation##########################################


##########################################################################################################################
#
# Exploratory adding age and position as features to determine if it makes sense to include in project(too complicated didn't do)
##########################################################################################

# ---------------------------
# SIDE ANALYSIS: Age & Position Effects (didn't do keeping here just to give the full context of my code for faculty review)
# ---------------------------







# ---------------------------
# Setup output directory
# ---------------------------
output_dir = "model_outputs"
os.makedirs(output_dir, exist_ok=True)

print("Starting modeling...") ### to help woth tracking where the code is in execution


# ---------------------------
# Prepare data
# ---------------------------
delta_cols = [c for c in df_features.columns if c.endswith("_delta")]
X = df_features[[c for c in df_features.columns if c not in delta_cols + ["player","player_id","injury_date","return_date"]]].fillna(0)
y = df_features[delta_cols].fillna(0)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ---------------------------
# Baseline KNN
# ---------------------------
knn = MultiOutputRegressor(KNeighborsRegressor())
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

# Metrics
mse_knn = mean_squared_error(y_test, y_pred_knn)
r2_knn = r2_score(y_test, y_pred_knn)
print(f"KNN Multi-Output Regression - MSE: {mse_knn:.3f}, R2: {r2_knn:.3f}")

# Save KNN scatter plots for each delta metric
for i, col in enumerate(delta_cols):
    plt.figure(figsize=(6, 6))
    plt.scatter(y_test[col], y_pred_knn[:, i], alpha=0.6)
    min_val = min(y_test[col].min(), y_pred_knn[:, i].min())
    max_val = max(y_test[col].max(), y_pred_knn[:, i].max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--')
    plt.xlabel(f"Actual {col}")
    plt.ylabel(f"Predicted {col}")
    plt.title(f"KNN: Actual vs Predicted ({col})")
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"knn_actual_vs_pred_{col}.png"))
    plt.close()

# ---------------------------
# Random Forest Hyperparameter Tuning
# ---------------------------
param_grid = {
    "estimator__n_estimators": [50, 100],
    "estimator__max_depth": [None, 5, 10],
}
rf = MultiOutputRegressor(RandomForestRegressor(random_state=42))
cv = KFold(n_splits=5, shuffle=True, random_state=42)
grid = GridSearchCV(rf, param_grid, cv=cv, scoring="r2", n_jobs=-1)
grid.fit(X_train, y_train)

best_rf = grid.best_estimator_
y_pred_rf = best_rf.predict(X_test)

# Metrics
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)
cv_r2 = cross_val_score(best_rf, X, y, cv=5, scoring="r2")
print(f"Random Forest Multi-Output Regression - MSE: {mse_rf:.3f}, R2: {r2_rf:.3f}")
print(f"5-fold CV R2: {cv_r2.mean():.3f} ± {cv_r2.std():.3f}")
print("Best RF params:", grid.best_params_)

# Save metrics
metrics_df = pd.DataFrame({
    "Model": ["KNN", "RandomForest"],
    "MSE": [mse_knn, mse_rf],
    "R2": [r2_knn, r2_rf],
    "CV_R2_Mean": [np.nan, cv_r2.mean()],
    "CV_R2_Std": [np.nan, cv_r2.std()]
})
metrics_df.to_csv(os.path.join(output_dir, "model_comparison.csv"), index=False)

# ---------------------------
# Feature Importance
# ---------------------------
importances = np.mean([est.feature_importances_ for est in best_rf.estimators_], axis=0)
feat_imp_df = pd.DataFrame({"feature": X.columns, "importance": importances}).sort_values("importance", ascending=False)
feat_imp_df.to_csv(os.path.join(output_dir, "rf_feature_importance.csv"), index=False)

plt.figure(figsize=(8,6))
sns.barplot(x="importance", y="feature", data=feat_imp_df.head(15))
plt.title("Top 15 Features by Importance (Random Forest)")
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "rf_top15_features.png"))
plt.close()

# Permutation importance
perm_importance = permutation_importance(best_rf, X_test, y_test, n_repeats=10, random_state=42)
perm_df = pd.DataFrame({"feature": X.columns, "importance_mean": perm_importance.importances_mean})
perm_df.sort_values("importance_mean", ascending=False).to_csv(os.path.join(output_dir, "rf_permutation_importance.csv"), index=False)

# ---------------------------
# Residual Analysis
# ---------------------------
residuals = y_test.values - y_pred_rf
residual_df = pd.DataFrame(residuals, columns=delta_cols)

# Boxplot of residuals
plt.figure(figsize=(10,6))
sns.boxplot(data=residual_df)
plt.xticks(rotation=45)
plt.title("Residuals by Delta Metric")
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "rf_residuals_boxplot.png"))
plt.close()

# Histogram of residuals
for col in delta_cols:
    plt.figure(figsize=(5,4))
    sns.histplot(residual_df[col], kde=True)
    plt.title(f"Residuals Distribution: {col}")
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"residual_hist_{col}.png"))
    plt.close()

# ---------------------------
# Feature Correlation Heatmap
# ---------------------------
plt.figure(figsize=(12,10))
sns.heatmap(X.corr(), cmap="coolwarm", center=0)
plt.title("Feature Correlation Matrix")
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "feature_correlation_heatmap.png"))
plt.close()

# ---------------------------
# KNN Neighbor Graph (improved PCA scatter based on feedback)
# ---------------------------
from sklearn.decomposition import PCA

scaler_knn = StandardScaler()
X_scaled = scaler_knn.fit_transform(X)

# Fit neighbor graph 
knn_nn = NearestNeighbors(n_neighbors=5)
knn_nn.fit(X_scaled)
distances, indices = knn_nn.kneighbors(X_scaled)

# PCA for 2D visualization (remember to report explained variance)
pca_vis = PCA(n_components=2, random_state=42)
X_pca_vis = pca_vis.fit_transform(X_scaled)
expl = pca_vis.explained_variance_ratio_

plt.figure(figsize=(8, 6))
palette = sns.color_palette("viridis", as_cmap=True)
hue_vals = y["PTS_delta"] if "PTS_delta" in y.columns else None
sns.scatterplot(
    x=X_pca_vis[:, 0],
    y=X_pca_vis[:, 1],
    hue=hue_vals,
    palette="viridis",
    alpha=0.8,
    s=45,
    edgecolor="white",
    linewidth=0.4,
    legend="brief"
)
plt.title("KNN Neighbor View in PCA Space (colored by ΔPTS)", loc="left", fontweight="bold")
plt.xlabel(f"PC1 ({expl[0]*100:.1f}% var)")
plt.ylabel(f"PC2 ({expl[1]*100:.1f}% var)")
leg = plt.legend(title="ΔPTS" if hue_vals is not None else None, frameon=False, bbox_to_anchor=(1.02, 1), loc="upper left")
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "knn_neighbor_pca_colored_by_dpts.png"), dpi=200, bbox_inches="tight")
plt.close()

# ================================
# Enhanced Clustering & Labeled PCA Plot + Cluster Profiles
# ================================
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, pairwise_distances


assert len(X) == len(df_features), "X and df_features must align row-wise."

# 
candidate_k = list(range(2, min(8, len(X))))  
sil_by_k = []
for k in candidate_k:
    try:
        km = KMeans(n_clusters=k, n_init=25, random_state=42)
        lbls = km.fit_predict(X_scaled)
        sil = silhouette_score(X_scaled, lbls)
        sil_by_k.append((k, sil))
    except Exception:
        sil_by_k.append((k, np.nan))

valid = [t for t in sil_by_k if not np.isnan(t[1])]
best_k = max(valid, key=lambda t: t[1])[0] if valid else 3
best_sil = dict(sil_by_k).get(best_k, np.nan)

#  Fit final KMeans nad PCA for plotting 
kmeans = KMeans(n_clusters=best_k, n_init=50, random_state=42)
cluster_id = kmeans.fit_predict(X_scaled)

# Use existing PCA 
try:
    X_pca_vis, expl  
except NameError:
    pca_vis = PCA(n_components=2, random_state=42)
    X_pca_vis = pca_vis.fit_transform(X_scaled)
    expl = pca_vis.explained_variance_ratio_

#  Build plotting DataFrame
vis_df = pd.DataFrame({
    "PC1": X_pca_vis[:, 0],
    "PC2": X_pca_vis[:, 1],
    "cluster_id": cluster_id,
    "player": df_features["player"].values
})
if "PTS_delta" in y.columns:
    vis_df["PTS_delta"] = y["PTS_delta"].values

# Select delta metrics to profile
delta_cols_for_profiles = [c for c in y.columns if c.endswith("_delta")] or \
                          [c for c in df_features.columns if c.endswith("_delta")]

# ) Numeric profiles by cluster
profiles = (
    pd.concat([vis_df["cluster_id"], df_features[delta_cols_for_profiles].reset_index(drop=True)], axis=1)
      .groupby("cluster_id")
      .mean()
)


def name_cluster(row):
    labels = []
    
    if "PTS_delta" in row:
        if row["PTS_delta"] <= -1.5: labels.append("Volume Drop")
        elif row["PTS_delta"] >= 0.8: labels.append("Volume Gain")
    # Efficiency 
    for eff_key, thr in [("EFF_delta", 1.0), ("FG_PCT_delta", 0.03), ("3P_PCT_delta", 0.03), ("FT_PCT_delta", 0.03)]:
        if eff_key in row:
            if row[eff_key] <= -thr: labels.append("Efficiency Drop")
            elif row[eff_key] >= thr: labels.append("Efficiency Gain")
            break
    
    if "MIN_delta" in row:
        if row["MIN_delta"] <= -3: labels.append("Minutes Down")
        elif row["MIN_delta"] >= 3: labels.append("Minutes Up")
    return " / ".join(labels) if labels else "Near-Baseline Returners"

cluster_name_map = {cid: name_cluster(profiles.loc[cid]) for cid in profiles.index}
vis_df["cluster_name"] = vis_df["cluster_id"].map(cluster_name_map)

# Main labeled clusters plot
sns.set_style("whitegrid")
plt.rcParams.update({"figure.dpi": 150, "font.size": 11})

fig, ax = plt.subplots(figsize=(8.8, 6.6))
palette = sns.color_palette("Set2", n_colors=best_k)
sns.scatterplot(
    data=vis_df, x="PC1", y="PC2",
    hue="cluster_name", palette=palette,
    alpha=0.85, s=45, edgecolor="white", linewidth=0.5, ax=ax
)

# Centroids and on plot labels
centroids_2d = vis_df.groupby("cluster_name")[["PC1", "PC2"]].mean().reset_index()
ax.scatter(centroids_2d["PC1"], centroids_2d["PC2"], s=220, marker="X", c="black", label="Centroid", zorder=3)
for _, r in centroids_2d.iterrows():
    ax.text(
        r.PC1, r.PC2, r["cluster_name"],
        fontsize=9, weight="bold", color="white",
        ha="center", va="center",
        bbox=dict(boxstyle="round,pad=0.25", fc="black", ec="none", alpha=0.7)
    )

# descriptor box with key deltas
desc_keys = [k for k in ["PTS_delta", "EFF_delta", "MIN_delta"] if k in profiles.columns]
for _, r in centroids_2d.iterrows():
  
    cid = vis_df.loc[vis_df["cluster_name"] == r["cluster_name"], "cluster_id"].mode().iloc[0]
    row = profiles.loc[cid, desc_keys]
    desc_text = "\n".join([f"Δ{c.replace('_delta','').upper()} {row[c]:+0.2f}" for c in desc_keys])
    ax.text(
        r.PC1, r.PC2 - 0.25, desc_text,
        fontsize=8, color="black", ha="center",
        bbox=dict(boxstyle="round,pad=0.25", fc="white", ec="lightgray")
    )

ax.set_title("Clustered Return‑to‑Play Patterns (PCA space)", loc="left", fontweight="bold")
ax.set_xlabel(f"PC1 ({expl[0]*100:.1f}% var)")
ax.set_ylabel(f"PC2 ({expl[1]*100:.1f}% var)")
ax.legend(title="Cluster (Profile)", frameon=False, bbox_to_anchor=(1.02, 1), loc="upper left")
ax.text(0.01, 0.01, f"Silhouette = {best_sil:.2f} | k={best_k}", transform=ax.transAxes, fontsize=9, color="gray")

plt.tight_layout()
plt.savefig(os.path.join(output_dir, "clusters_pca_labeled.png"), dpi=200, bbox_inches="tight")
plt.close()

# 6) Exemplar labels (closest to centroid) – saved separately to avoid clutter
fig, ax = plt.subplots(figsize=(8.8, 6.6))
sns.scatterplot(
    data=vis_df, x="PC1", y="PC2",
    hue="cluster_name", palette=palette,
    alpha=0.85, s=45, edgecolor="white", linewidth=0.5, ax=ax
)
exemplars = []
for cname, g in vis_df.groupby("cluster_name"):
    cen = centroids_2d.loc[centroids_2d["cluster_name"] == cname, ["PC1", "PC2"]].values
    d = pairwise_distances(g[["PC1", "PC2"]], cen)
    i = g.index[d.argmin()]
    exemplars.append(vis_df.loc[i])

for _, row in pd.DataFrame(exemplars).iterrows():
    ax.annotate(
        row["player"],
        (row["PC1"], row["PC2"]),
        xytext=(6, 7), textcoords="offset points",
        fontsize=8, color="black",
        bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="gray", alpha=0.85)
    )

ax.set_title("Clustered Patterns with Exemplar Players", loc="left", fontweight="bold")
ax.set_xlabel(f"PC1 ({expl[0]*100:.1f}% var)")
ax.set_ylabel(f"PC2 ({expl[1]*100:.1f}% var)")
ax.legend(title="Cluster (Profile)", frameon=False, bbox_to_anchor=(1.02, 1), loc="upper left")
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "clusters_pca_labeled_exemplars.png"), dpi=200, bbox_inches="tight")
plt.close()

# 7) Cluster profile chart (what makes clusters different?)
prof_long = (
    profiles.reset_index()
            .rename(columns={"cluster_id": "cluster"})
            .melt(id_vars="cluster", var_name="metric", value_name="mean_delta")
)
plt.figure(figsize=(9.5, 5.8))
sns.barplot(data=prof_long, x="metric", y="mean_delta", hue="cluster", palette="Set2")
plt.axhline(0, color="gray", linewidth=1)
plt.title("Cluster Profiles: Mean Post–Pre Deltas", loc="left", fontweight="bold")
plt.xlabel(""); plt.ylabel("Mean Delta")
plt.legend(title="Cluster", bbox_to_anchor=(1.02, 1), loc="upper left", frameon=False)
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "cluster_profiles_bar.png"), dpi=200, bbox_inches="tight")
plt.close()

# 8) table (for final paper)
profiles_rounded = profiles.round(3)
profiles_rounded.index = profiles_rounded.index.map(lambda cid: f"{cid} — {cluster_name_map[cid]}")
profiles_rounded.to_csv(os.path.join(output_dir, "cluster_profiles_table.csv"))




###### Remember to come back and enhance code for charts to make them more presentable for final presentation ############################